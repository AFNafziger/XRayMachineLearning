# -*- coding: utf-8 -*-
"""capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j_2AhGqt6F6Lwi-QOiP9jTU5FUlmuXiD

#Exploratory Data

Mery, D.; Riffo, V.; Zscherpel, U.; Mondrag√≥n, G.; Lillo, I.; Zuccar, I.; Lobel, H.; Carrasco, M. (2015): GDXray: The database of X-ray images for nondestructive testing. Journal of Nondestructive Evaluation, 34.4:1-12.
"""

# Commented out IPython magic to ensure Python compatibility.
import keras
from keras.datasets import mnist
from keras.layers import Dense
from keras.models import Sequential
import tensorflow as tf
from matplotlib import pyplot as plt
from random import randint
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams['figure.figsize'] = [6, 4]
sns.set(color_codes=True)
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.layers import Dense
from keras.models import Sequential
import tensorflow as tf
from matplotlib import pyplot as plt
from random import randint
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.svm import SVR
plt.rcParams['figure.figsize'] = [16, 16]
sns.set(color_codes=True)
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import keras
from keras.datasets import mnist
from keras.layers import Dense
from keras.models import Sequential
import tensorflow as tf
from matplotlib import pyplot as plt
from random import randint
from matplotlib import pyplot as plt
from random import randint
import numpy as np
import warnings # supress warnings
warnings.filterwarnings('ignore')
from matplotlib import image
from matplotlib import pyplot
from PIL import Image
import os, os.path
from pathlib import Path
from PIL import Image, ImageOps
from keras.preprocessing.image import img_to_array


fname = '/content/drive/MyDrive/mlCapstone/Dangerous'
dan = fname
notdan = '/content/drive/MyDrive/mlCapstone/NotDangerous'
ndan = notdan

image = image.imread(dan+'/B0001_0001.png')

pyplot.imshow(image)
pyplot.show()

path1 = "/MyDrive/mlCapstone/Dangerous"
path2 = "/MyDrive/mlCapstone/NotDangerous"
imgsD = []
imgsN = []

for dirpath, dirnames, filenames in os.walk(dan):
    for filename in filenames:
        if filename.endswith('.png'):
            imageR = Image.open(os.path.join(dirpath, filename))
            imageR = img_to_array(imageR)
            imageR = np.reshape(imageR, (-1,64))
            imgsD.append(imageR)

for dirpath, dirnames, filenames in os.walk(ndan):
    for filename in filenames:
        if filename.endswith('.png'):
            imageR = Image.open(os.path.join(dirpath, filename))
            imageR = img_to_array(imageR)
            imageR = np.reshape(imageR, (-1,64))
            imgsN.append(imageR)

len(imgsD)

len(imgsN)

print(imgsD[3])

imgsD[3].shape

imgsN[3].shape

ones = []
t = 0
while t <9711:
  ones.append(1)
  t = t +1
zeros = []
t = 0
while t <11267:
  zeros.append(0)
  t = t +1

Ydata = ones + zeros
Ydata = np.asarray(Ydata)
Xdata = imgsD + imgsN
Xdata = np.asarray(Xdata)

SXdata = Xdata
SYdata = Ydata
CXdata = Xdata
CYdata = Ydata

Xdata.shape

CXdata = CXdata.reshape(20978, 64, 64, 1)

num_classes = 2
CYdata = tf.keras.utils.to_categorical(CYdata, num_classes)

len(Xdata)

for i in range(64):
    ax = plt.subplot(8, 8, i+1)
    ax.axis('off')
    plt.imshow(Xdata[randint(0, Xdata.shape[0])], cmap='Greys')

"""#Multilayer NN"""

image_size = 4096
Xdata = Xdata.reshape(Xdata.shape[0], image_size)



num_classes = 2
Ydata = tf.keras.utils.to_categorical(Ydata, num_classes)

X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata, test_size=0.25, random_state=1)

model = Sequential()

model.add(Dense(units=4096, activation='sigmoid', input_shape=(image_size,)))
model.add(Dense(units=4096, activation='sigmoid'))
model.add(Dense(units=num_classes, activation='softmax'))

model.summary()

model.compile(optimizer="sgd", loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, batch_size=100, epochs=10, verbose=True, validation_split=.1)
loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training', 'validation'], loc='best')
plt.show()

print(f'Test loss: {loss:.3}')
print(f'Test accuracy: {accuracy:.3}')

y_pred=model.predict(X_test)
y_pred=np.argmax(y_pred, axis=1)
y_test=np.argmax(y_test, axis=1)

cm = metrics.confusion_matrix(y_test, y_pred)
print(cm)

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # name  of classes
fig, ax = plt.subplots(figsize=(8, 8))
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="coolwarm" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix Softmax Function', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

"""#Suppor Vector Machine"""

SXdata.shape

image_size = 4096
SXdata = SXdata.reshape(Xdata.shape[0], image_size)

SXdata.shape

X_train, X_test, y_train, y_test = train_test_split(SXdata, SYdata, test_size=0.2, random_state=100)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.svm import SVC

workingSVC = SVC(kernel='rbf', C=1)
workingSVC.fit(X_train,y_train)

y_pred = workingSVC.predict(X_test)
print(metrics.classification_report(y_test, y_pred))

y_pred = workingSVC.predict(X_test)
workingSVC.score(X_test, y_test)

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # name  of classes
fig, ax = plt.subplots(figsize=(8, 8))
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="coolwarm" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix Softmax Function', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

"""#Improved CNN"""

import keras
from keras.datasets import mnist
from keras.layers import Dense
from keras.models import Sequential
from keras.layers import Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Activation, Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten
from tensorflow.keras.layers import BatchNormalization

X_train, X_test, y_train, y_test = train_test_split(CXdata, CYdata, test_size=0.25, random_state=1)

model = Sequential()                                 # Linear stacking of layers

# Convolution Layer 1
model.add(Conv2D(32, (3, 3), input_shape=(64,64,1))) # 32 different 3x3 kernels -- so 32 feature maps
model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation
convLayer01 = Activation('relu')                     # activation
model.add(convLayer01)

# Convolution Layer 2
model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps
model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation
model.add(Activation('relu'))                        # activation
convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel
model.add(convLayer02)



model.add(Conv2D(64,(3, 3)))
model.add(BatchNormalization(axis=-1))
convLayer03 = Activation('relu')
model.add(convLayer03)


model.add(Conv2D(64, (3, 3)))
model.add(BatchNormalization(axis=-1))
model.add(Activation('relu'))
convLayer04 = MaxPooling2D(pool_size=(2,2))
model.add(convLayer04)
model.add(Flatten())


model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))


model.add(Dense(512))
model.add(BatchNormalization())
model.add(Activation('relu'))


model.add(Dropout(0.1))
model.add(Dense(2))
model.add(Activation('softmax'))

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,
                         height_shift_range=0.08, zoom_range=0.08)

test_gen = ImageDataGenerator()

X_train.shape

train_generator = gen.flow(X_train, y_train, batch_size=128)
test_generator = test_gen.flow(X_test, y_test, batch_size=128)

model.fit(train_generator, steps_per_epoch=13733//128, epochs=20, verbose=1,
                    validation_data=test_generator, validation_steps=2000//128)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training', 'validation'], loc='best')
plt.show()

print(f'Test loss: {loss:.3}')
print(f'Test accuracy: {accuracy:.3}')

y_pred=model.predict(X_test)
y_pred=np.argmax(y_pred, axis=1)
y_test=np.argmax(y_test, axis=1)

cm = metrics.confusion_matrix(y_test, y_pred)
print(cm)

class_names=[0,1] # name  of classes
fig, ax = plt.subplots(figsize=(8, 8))
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cm), annot=True, cmap="coolwarm" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix Softmax Function', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

"""#Convolutional Neural Network"""